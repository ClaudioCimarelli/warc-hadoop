<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_51) on Mon May 05 23:35:52 BST 2014 -->
<title>Overview (warc-hadoop 0.1.0 API)</title>
<meta name="date" content="2014-05-05">
<link rel="stylesheet" type="text/css" href="stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="Overview (warc-hadoop 0.1.0 API)";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li class="navBarCell1Rev">Overview</li>
<li>Package</li>
<li>Class</li>
<li><a href="overview-tree.html">Tree</a></li>
<li><a href="deprecated-list.html">Deprecated</a></li>
<li><a href="index-all.html">Index</a></li>
<li><a href="help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev</li>
<li>Next</li>
</ul>
<ul class="navList">
<li><a href="index.html?overview-summary.html" target="_top">Frames</a></li>
<li><a href="overview-summary.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<div class="header">
<h1 class="title">warc-hadoop 0.1.0 API</h1>
</div>
<div class="header">
<div class="subTitle">
<div class="block">WARC Input and Output Formats for Hadoop</div>
</div>
<p>See: <a href="#overview_description">Description</a></p>
</div>
<div class="contentContainer">
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Packages table, listing packages, and an explanation">
<caption><span>Packages</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Package</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tbody>
<tr class="altColor">
<td class="colFirst"><a href="com/martinkl/warc/package-summary.html">com.martinkl.warc</a></td>
<td class="colLast">
<div class="block">Common implementation of reading and writing files in WARC format.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><a href="com/martinkl/warc/mapred/package-summary.html">com.martinkl.warc.mapred</a></td>
<td class="colLast">
<div class="block">Input and output formats using Hadoop&rsquo;s &lsquo;old&rsquo; (mapred) API.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><a href="com/martinkl/warc/mapreduce/package-summary.html">com.martinkl.warc.mapreduce</a></td>
<td class="colLast">
<div class="block">Input and output formats using Hadoop&rsquo;s &lsquo;new&rsquo; (mapreduce) API.</div>
</td>
</tr>
</tbody>
</table>
</div>
<div class="footer"><a name="overview_description">
<!--   -->
</a>
<div class="subTitle">
<div class="block"><h1>WARC Input and Output Formats for Hadoop</h1><p>This is a simple library for working with <a href="http://en.wikipedia.org/wiki/Web_ARChive">WARC (Web Archive)</a> files in Hadoop. It provides InputFormats for reading and OutputFormats for writing WARC files in MapReduce jobs (supporting both the &lsquo;old&rsquo; <code>org.apache.hadoop.mapred</code> and the &lsquo;new&rsquo; <code>org.apache.hadoop.mapreduce</code> API).</p><p>WARC files are used to record the activity of a web crawler. They include both the HTTP requests that were sent to servers, and the HTTP response received (including headers). WARC is an <a href="http://bibnum.bnf.fr/warc/WARC_ISO_28500_version1_latestdraft.pdf">ISO standard</a>, and is used (amongst others) by the <a href="https://archive.org/details/ExampleArcAndWarcFiles">Internet Archive</a> and <a href="http://commoncrawl.org/navigating-the-warc-file-format/">CommonCrawl</a>.</p><p>This warc-hadoop library was written in order to explore the <a href="http://commoncrawl.org/">CommonCrawl</a> data, a publicly available dump of billions of web pages. The data is made available for free as a <a href="https://aws.amazon.com/datasets/41740">public dataset</a> on AWS. If you want to process it, you just need to pay for the computing capacity of processing it on AWS, or for the network bandwidth to download it.</p><h2>Using warc-hadoop</h2><p>At the moment you have to build it from source, but hopefully I can get it published to a Maven repository soon. For now:</p>
<pre><code class="no-highlight">$ git clone https://github.com/ept/warc-hadoop.git
$ cd warc-hadoop
$ ./gradlew install
</code></pre><p>Then add the following Maven dependency to your project:</p>
<pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;com.martinkl.warc&lt;/groupId&gt;
    &lt;artifactId&gt;warc-hadoop&lt;/artifactId&gt;
    &lt;version&gt;0.1.0&lt;/version&gt;
&lt;/dependency&gt;
</code></pre><p>Now you can import either <code>com.martinkl.warc.mapred.WARCInputFormat</code> or <code>com.martinkl.warc.mapreduce.WARCInputFormat</code> into your Hadoop job, depending on which version of the API you are using. Example usage:</p>
<pre><code class="java">JobConf job = new JobConf(conf, CommonCrawlTest.class);

FileInputFormat.addInputPath(job, new Path(&quot;/path/to/my/input&quot;));
FileOutputFormat.setOutputPath(job, new Path(&quot;/path/for/my/output&quot;));
FileOutputFormat.setCompressOutput(job, true);

job.setInputFormat(WARCInputFormat.class);
job.setOutputFormat(WARCOutputFormat.class);
job.setOutputKeyClass(NullWritable.class);
job.setOutputValueClass(WARCWritable.class);
</code></pre><p>Example of a mapper that emits server responses, using the URL as the key:</p>
<pre><code class="java">public static class MyMapper extends MapReduceBase
        implements Mapper&lt;LongWritable, WARCWritable, Text, WARCWritable&gt; {

    public void map(LongWritable key, WARCWritable value, OutputCollector&lt;Text, WARCWritable&gt; collector,
                    Reporter reporter) throws IOException {
        String recordType = value.getRecord().getHeader().getRecordType();
        String targetURL  = value.getRecord().getHeader().getTargetURI();

        if (recordType.equals(&quot;response&quot;) &amp;&amp; targetURL != null) {
            collector.collect(new Text(targetURL), value);
        }
    }
}
</code></pre><h2>File format parsing</h2><p>A WARC file consists of a flat sequence of records. Each record may be a HTTP request (<code>recordType = &quot;request&quot;</code>), a response (<code>recordType = &quot;response&quot;</code>) or one of various other types, including metadata. When reading from a WARC file, the records are given to the mapper one at a time. That means that the request and the response will appear in two separate calls of the <code>map</code> method.</p><p>This library currently doesn&rsquo;t perform any parsing of the data inside records, such as the HTTP headers or the HTML body. You can simply read the server&rsquo;s response as an array of bytes. Additional parsing functionality may be added in future versions.</p><p>WARC files are typically gzip-compressed. Gzip files are not splittable by Hadoop (i.e. an entire file must be processed sequentially, it&rsquo;s not possible to start reading in the middle of a file) so projects like CommonCrawl typically aim for a maximum file size of 1GB (compressed). If you&rsquo;re only doing basic parsing, a file of that size takes less than a minute to process.</p><p>When writing WARC files, this library automatically splits output files into gzipped segments of approximately 1GB. You can customize the segment size using the configuration key <code>warc.output.segment.size</code> (the value is the target segment size in bytes).</p><h2>Meta</h2><p>(c) 2014 Martin Kleppmann. MIT License.</p><p>Please submit pull requests to the <a href="https://github.com/ept/warc-hadoop">Github project</a>.</p></div>
</div>
</div>
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li class="navBarCell1Rev">Overview</li>
<li>Package</li>
<li>Class</li>
<li><a href="overview-tree.html">Tree</a></li>
<li><a href="deprecated-list.html">Deprecated</a></li>
<li><a href="index-all.html">Index</a></li>
<li><a href="help-doc.html">Help</a></li>
</ul>
<div class="aboutLanguage"><em><script type="text/javascript" src="./highlight.pack.js"></script>
<script type="text/javascript"><!--
hljs.initHighlightingOnLoad();
//--></script></em></div>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev</li>
<li>Next</li>
</ul>
<ul class="navList">
<li><a href="index.html?overview-summary.html" target="_top">Frames</a></li>
<li><a href="overview-summary.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
